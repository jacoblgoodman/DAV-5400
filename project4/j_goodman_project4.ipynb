{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Data Acquisition, Data Preparation & Exploratory Data Analysis\n",
    "\n",
    "## 1. Environment Set Up and Data Acquisition:\n",
    "\n",
    "To get set up we will follow the following steps:\n",
    "\n",
    "1. Load the packages we need for phase 1\n",
    "2. Scrape the column names:\n",
    "    1. make a request to the names file\n",
    "    2. regex to capture column names\n",
    "    3. remove extra information that was grabbed in scrape\n",
    "    4. insert `poisonous` in first position (it was excluded as it is not an attribute )\n",
    "3.  Acquire data and combine with 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 package loading:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "# get columns names froms names file\n",
    "#location of names\n",
    "http = 'https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.names'\n",
    "#request to names file\n",
    "req = requests.request('get',url = http)\n",
    "#search to match columns\n",
    "search = re.compile('[0-9]{1,2}. ([-?\\w]+):')\n",
    "#finding based on search dropping some extra data\n",
    "names = search.findall(req.text)[3:]\n",
    "#inserting poisonous which was not listed in attribute list\n",
    "names.insert(0,'poisonous')\n",
    "\n",
    "#created data frame with data plus names derived above\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data',names = names)\n",
    "\n",
    "#sanity check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Prep Feature Engineering:\n",
    "\n",
    "As we read about in [Week13 readings](https://elitedatascience.com/feature-engineering)  and in class there are several processes that we should embark on before doing any predictions on a data set. These include:\n",
    "\n",
    "- Subsetting - the features we plan on utilizing in our model are the only ones we will process to simplify everything below\n",
    "- Handling missing data - most modeling algorithms require data that is free from gaps (no nulls)\n",
    "- Combining sparse classes - categorical classes that have very few records can lead to overfit models \n",
    "- Adding dummy variables - for each categorical value we will create a boolean indicator value\n",
    "\n",
    "###  Subsetting:\n",
    "\n",
    "Now that we have all the data we are ready to do some prep. First we will create the subset with the following features:\n",
    "\n",
    "1. `Poisonous` - our outcome of interest\n",
    "2. `Odor` (required as part of assignment)\n",
    "3. `Spore-print-color` (selected because I know how useful this is in mushroom identification)\n",
    "4. `Bruises?` (as I know some mushrooms with volatile chemicals in them react to air I am curious if this can be utlized to predict poisonousness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting collumns\n",
    "columns = ['poisonous','odor','bruises?', 'spore-print-color']\n",
    "#creating subset\n",
    "df_for_pred = df.loc[:,columns]\n",
    "#sanity check\n",
    "df_for_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking For Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_pred.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The dataset is free from nulls.\n",
    "\n",
    "\n",
    "\n",
    "### Combining Sparse Classes \n",
    "#### Initial Visualizing:\n",
    "\n",
    "To aid in identifying sparse classes and learning more about our data we will create visualizations of each of our data points. As they are all categorical, these will be bar charts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barchart of subset variables\n",
    "plt.figure(figsize=(12,12));\n",
    "plt.suptitle('Variable bar charts',fontsize=24)\n",
    "plt.tight_layout();\n",
    "plt.subplot(2,2,1);\n",
    "sns.countplot(x='poisonous', data = df_for_pred);\n",
    "plt.subplot(2,2,2);\n",
    "sns.countplot(x='odor', data=df_for_pred);\n",
    "plt.subplot(2,2,3);\n",
    "sns.countplot(x='bruises?', data=df_for_pred);\n",
    "plt.subplot(2,2,4);\n",
    "sns.countplot(x='spore-print-color',data=df_for_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:** \n",
    "\n",
    "**Sparse Classes:**  \n",
    "The `spore-print-color` variable appears to have several sparse classes that we should investigate combining. Odor could also be considered but will be excluded as it is included at the driection of the assignment's documentation and there is no mention of this process in the directions provided.\n",
    "\n",
    "**Other:**   \n",
    "Other conclusions that can be taken out of this initial look at our data:\n",
    "`Poisonous` - our observations appear to be approximately evenly distributed. \n",
    "  \n",
    "#### Counting\n",
    "We will next look at the value counts and decide what classes from `spore-print-color` to combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_for_pred['spore-print-color'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining spares classes\n",
    "\n",
    "The classes `r, u, b, o , y` will all be combined into a variable `other`. They all have a fraction of the number of observations of the other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting sparse to other with isin method \n",
    "df_for_pred.loc[df_for_pred['spore-print-color'].isin(['r','u','b','o','y']),'spore-print-color'] = 'other'\n",
    "\n",
    "#sanity check \n",
    "display(df_for_pred['spore-print-color'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding dummy variables: \n",
    "\n",
    "All of our variables will require some modification to make them ready for predictive modeling.\n",
    "\n",
    "- `Poisonous`: as it has only 2 values we will make an in-line update and set P = to 1 and E = to 0 \n",
    "\n",
    "- `Bruises?`: has two values T/F we will make t = 1 and f = 0\n",
    "\n",
    "- `spore-print-color` and `odor` have `14` values between them (after combining sparse classes) so we will utilize the `.get_dummies` pandas function to split them into indicator variables so that our **analytical base table (ABT)** will contain `16` columns.\n",
    "\n",
    "#### 1. Poisonous & Bruises?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting Poisonous = p to 1\n",
    "df_for_pred.poisonous = (df_for_pred.poisonous == 'p').astype(int)\n",
    "#verification\n",
    "df_for_pred.poisonous.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting bruises? = t to 1\n",
    "df_for_pred['bruises?'] = (df_for_pred['bruises?'] =='t').astype(int)\n",
    "\n",
    "#sanity check \n",
    "df_for_pred['bruises?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `Spore-Print-color` & `Odor` Get_Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummies function\n",
    "df_with_dummies = pd.get_dummies(df_for_pred)\n",
    "#sanity check\n",
    "df_with_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA: Exploratory Data Analysis: \n",
    "\n",
    "We will now finish the exploratory analysis [started above](#Initial-visualizing%3A) by looking at the relationship between our indicator (`Poisonous`) and  our predictor values.\n",
    "### 1. Bruises & Poisonous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot('bruises?',col ='poisonous',kind='count',data=df_for_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:**\n",
    "\n",
    "Mushrooms that bruise appear to be more likely to not be poisonous and mushrooms that don't bruise appear to be much more likely to be poisonous \n",
    "\n",
    "### 2. Spore Print Color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax= pd.crosstab(df_for_pred['spore-print-color'],df_for_pred.poisonous).plot.bar(figsize=(10,6));           \n",
    "ax.legend(['not poisonous','poisonous'],loc = 0,framealpha = .6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:**\n",
    "\n",
    "Spore print colors `h` and `w` appear to be significantly more likely to be poisonous, while `k`, `n` & `other` are much more likely to be not poisonous. \n",
    "\n",
    "### 3. Odor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.crosstab(df_for_pred.odor,df_for_pred.poisonous)\n",
    "ax = table.div(table.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True,figsize=(10,6))\n",
    "plt.xticks(rotation=0);\n",
    "ax.legend(['not poisonous','poisonous'],loc = 5,framealpha = .6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**conclusions:**\n",
    "\n",
    "While odor `n` is highly correlated to being not poisonous it is the worst predictor of the group the rest of the odor variables are perfect predictors of whether a mushroom is poisonous or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA conclusions\n",
    "\n",
    "While `Bruises?` and `sport print color` have some correlation to whether a mushroom is poisonous `odor`has a Very strong correlation and will be the strongest predictor of the bunch.\n",
    "\n",
    "____\n",
    "\n",
    "# Phase 2: Build Predictive Models\n",
    "\n",
    "to build our models we will follow the following process:\n",
    "\n",
    "1. Load packages\n",
    "\n",
    "2. Set indicator variable to a variable `y` \n",
    "\n",
    "   ​\twe will first set our predicator to an array called `y` \n",
    "\n",
    "3. We will now set our predictors\n",
    "\n",
    "   1. Set all columns except `poisonous` from our ABT table  into `predictors`\n",
    "   2. Use `predictors` to create an array containing our predictor values `X` \n",
    "\n",
    "4. Find our null error rate\n",
    "\n",
    "   we will calculate the null error rate of the data ($sum poisonous/total number of observations$) so that we can compare our models performance against chance.\n",
    "\n",
    "5. Initialize a model \n",
    "6. Fit the model\n",
    "7. Predict \n",
    "8. Evaluate\n",
    "9. repeat with other treatments (different columns) \n",
    "\n",
    "## Steps 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.load the LogisticRegression and metrics functions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "#2. set y varible with poisonous \n",
    "y  = df_with_dummies.poisonous.values\n",
    "#3.A set a predictors varible starting with all varibles \n",
    "predictors = df_with_dummies.columns.values[1:]\n",
    "#3.B set a x_train varible \n",
    "X = df_with_dummies[predictors].values\n",
    "\n",
    "#sanity check x_train\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saniy check Y_train\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Null Error Rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_error = df_with_dummies.poisonous.sum()/df_with_dummies.shape[0]\n",
    "print(f'the null error rate of our initial data is:\\n{null_error:.2} percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Initialize A Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a Logistic \n",
    "model = LogisticRegression(solver = 'lbfgs') # set to remove warning and set to soon to be new default "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 Fit Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 8 evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,p in enumerate(predictors):\n",
    "    print(f'{p} = {model.coef_[0][e]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:**\n",
    "we have created a model that is 98.5% accurate. we will now see if we can do better\n",
    "## steps 5-7 with different predictors\n",
    "we will now evaluate whether we get a better result by dropping the Spore Color attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df_with_dummies.columns.values[1:11]\n",
    "#3.B set a x_train varible\n",
    "X = df_with_dummies[predictors].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_spores = LogisticRegression(solver = 'lbfgs') # set to remove warning and set to soon to be new default\n",
    "\n",
    "no_spores.fit(X,y)\n",
    "\n",
    "print(no_spores.score(X,y))\n",
    "y_pred_no_spores = no_spores.predict(X)\n",
    "print(metrics.classification_report(y,y_pred_no_spores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,p in enumerate(predictors):\n",
    "    print(f'{p} = {no_spores.coef_[0][e]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**conclusions:** \n",
    "removing the spores attributes had NO effect in improving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps 5-7 with Different Predictors\n",
    "we will now evaluate whether we get a better result by dropping the `Bruises?` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df_with_dummies.columns.values[2:11]\n",
    "#3.B set a x_train varible \n",
    "X = df_with_dummies[predictors].values \n",
    "\n",
    "odor = LogisticRegression(solver = 'lbfgs') # set to remove warning and set to soon to be new default\n",
    "\n",
    "odor.fit(X,y)\n",
    "\n",
    "print(odor.score(X,y))\n",
    "y_pred_odor = odor.predict(X)\n",
    "print(metrics.classification_report(y,y_pred_odor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,p in enumerate(predictors):\n",
    "    print(f'{p} = {odor.coef_[0][e]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**conclusions**\n",
    "Dropping Bruises? does not increase the accuracy of the model\n",
    "\n",
    "**next**\n",
    "we will evaluate spore color on its own as a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df_with_dummies.columns.values[12:]\n",
    "#3.B set a x_train varible \n",
    "X = df_with_dummies[predictors].values \n",
    "\n",
    "spores = LogisticRegression(solver = 'lbfgs') # set to remove warning and set to soon to be new default\n",
    "\n",
    "spores.fit(X,y)\n",
    "\n",
    "print(spores.score(X,y))\n",
    "y_pred_spores = spores.predict(X)\n",
    "print(metrics.classification_report(y,y_pred_spores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,p in enumerate(predictors):\n",
    "    print(f'{p} = {spores.coef_[0][e]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**conclusions**  \n",
    "Spore color is relatively accurate predictor returning a model that is 85.9% accurate.\n",
    "**next**  \n",
    "we will see if adding bruise? to this model increases its accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df_with_dummies.columns.values[[1,12,13,14,15]]\n",
    "#set a x_train varible \n",
    "X = df_with_dummies[predictors].values \n",
    "\n",
    "spores_bruises = LogisticRegression(solver = 'lbfgs') # set to remove warning and set to soon to be new default\n",
    "\n",
    "spores_bruises.fit(X,y)\n",
    "\n",
    "print(spores_bruises.score(X,y))\n",
    "y_pred_spores_bruises = spores_bruises.predict(X)\n",
    "print(metrics.classification_report(y,y_pred_spores_bruises))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,p in enumerate(predictors):\n",
    "    print(f'{p} = {sprores_bruises.coef_[0][e]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**conclusions**\n",
    "Adding bruises does not increase the effect of the model\n",
    "**final** \n",
    "bruises will be evaluated on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df_with_dummies.columns.values[[1]]\n",
    "#set a x_train varible \n",
    "X = df_with_dummies[predictors].values \n",
    "\n",
    "bruises = LogisticRegression(solver = 'lbfgs') # set to remove warning and set to soon to be new default\n",
    "\n",
    "bruises.fit(X,y)\n",
    "\n",
    "print(bruises.score(X,y))\n",
    "y_pred_bruises = bruises.predict(X)\n",
    "print(metrics.classification_report(y,y_pred_bruises))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,p in enumerate(predictors):\n",
    "    print(f'{p} = {bruises.coef_[0][e]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Conclusion and Next Steps:\n",
    "\n",
    "We conclude that `odor` is the strongest predictor of whether a mushroom will be poisonous or not with the ability  to predict Poisonousness to an accuracy of  98% (based on our current data set). The null value was 48%. \n",
    "\n",
    "As for our other attributes, while they might not be bad predictors of poisonousness themselves (spore color (86.9% accuracy) , bruises(74.3% accuracy))  they did not increase the predictive power of `odor`.\n",
    "\n",
    "**Recommendations for next steps**\n",
    "\n",
    "- there are 19 other attributes that should be evaluated for their predictive capabilities\n",
    "- looking for interaction effects among variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
